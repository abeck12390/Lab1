{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb13e98b-52a2-4268-a9ff-6849d26659c0",
   "metadata": {},
   "source": [
    "\\section*{4.1 Bias Frames}\n",
    "Section 4.1 is the analysis for bias frames. In this we will calculate the amount of read out noise from the CCD and identify any hot pixels to be used for later calibration. I first loaded the bias fits file into python so to create a histogram.\n",
    "\n",
    "To find the average number of counts per pixel I used python to create a histogram of the number of counts per pixel of the bias image. When plotted with a log y-axis it is easier to determine where the majority of counts are, as there is a peak that is over two orders of magnitude higher than the background. For this set of data I decided to cut off any data points that had more than 1300 counts. The fraction of pixels that were over 1300 counts was $1.62 * 10^{-5}$. I used the width of this peak to determine where the cutoff for the data for the gaussian should be. For this bias image I used data between 950 counts and 1050 counts. Using all the pixels that had counts within that range I calculated the mean and standard deviation which were $\\mu = 985.9$ counts and $\\sigma = 8.1$ counts\n",
    "\n",
    "The gain listed in the images header was 2.06. Converting this to number of electrons results $N_{electrons}=GN_{counts}=8.1*2.06=16.7 \\,e-$. The listed read out noise on the spec sheet is $14.8e-$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba35800-738b-46cc-b8db-855ba331320a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction 1.621246337890625e-05\n",
      "mu 985.923783029866\n",
      "sig 8.098709046392562\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "bias_image=fits.open('0cbias.FIT')\n",
    "bias_1d = bias_image[0].data.flatten()\n",
    "\n",
    "cmin=950\n",
    "cmax=1200\n",
    "nbins=100\n",
    "normalization=(cmax-cmin)/nbins*len(bias_1d[(bias_1d>=cmin) & (bias_1d<=cmax)])\n",
    "\n",
    "clipmin=cmin\n",
    "clipmax=1030\n",
    "clippedvalues = bias_1d[(bias_1d>=clipmin) & (bias_1d<=clipmax)]\n",
    "\n",
    "cutvalues = bias_1d[(bias_1d>=1300)]\n",
    "fraction_pix = len(cutvalues)/len(bias_1d)\n",
    "print(\"fraction \" + str(fraction_pix))\n",
    "\n",
    "mu=np.mean(clippedvalues)\n",
    "sig=np.std(clippedvalues)\n",
    "mode=stats.mode(clippedvalues)[0][0]\n",
    "\n",
    "print('mu ' + str(mu))\n",
    "print('sig ' + str(sig))\n",
    "\n",
    "xarray=np.linspace(cmin,cmax,nbins*10)\n",
    "yarray=normalization*norm.pdf(xarray,loc=mu, scale=sig)\n",
    "\n",
    "plt.hist(bias_1d,range=[cmin,cmax], bins=nbins);\n",
    "plt.yscale('log')\n",
    "plt.ylim([0.1,1e6])\n",
    "plt.plot(xarray,yarray,color=\"red\",linewidth=3.0)\n",
    "plt.axvline(x=mode,linewidth=3.0,color=\"yellow\")\n",
    "\n",
    "header = bias_image[0].header\n",
    "gain = header['EGAIN']\n",
    "muNelectron = gain * sig\n",
    "#print(muNelectron)\n",
    "\n",
    "plt.xlabel('Number of counts per pixel (e/p)')\n",
    "plt.ylabel('NUmber of pixels')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a572795f-a803-4100-9481-40a59910fca0",
   "metadata": {},
   "source": [
    "\\section{4.2 Dark Frames}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e820d155-f5a2-4fc9-8cdc-68964c9bcc88",
   "metadata": {},
   "source": [
    "Part 1 Creating the master dark:\n",
    "To create the master dark I first loaded all 10 darks into python, then I could loop trhough every pixel and find the median count value from all 10 darks. That median was then loaded into a new master dark array and after evaluating over every pixel I had a new array whos data in each pixel was the median value. I then made a new master dark FITS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758589e-7e05-4bdd-ac7d-06f3db168248",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "data= np.zeros((10, 1024, 1024))\n",
    "master_dark = np.zeros((1024,1024))\n",
    "for i in range (0,10):\n",
    "    file = \"10dark_\" + str(i) +\".FIT\"\n",
    "    dark = fits.open(file)\n",
    "    current_dark=dark[0].data\n",
    "    #print(current_dark)\n",
    "    for n in range(0,1024):\n",
    "        for j in range(0,1024):\n",
    "            data[i,n,j]=current_dark[n,j]\n",
    "\n",
    "median_list=[]\n",
    "for n in range(0,1024):\n",
    "    for j in range(1024):\n",
    "        median_list.clear()\n",
    "        for i in range(0,10):\n",
    "            median_list.append(data[i,n,j])\n",
    "        master_dark[n,j] = np.median(median_list)\n",
    "print(master_dark)\n",
    "\n",
    "new_dark = fits.PrimaryHDU(master_dark)\n",
    "new_dark.writeto('master_dark.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c13ea9-0d56-406a-bf29-2835bb2ee883",
   "metadata": {},
   "source": [
    "Part 2 Time series of dark frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f7e1a-a9e6-442e-98df-cb8ee7ab7a07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "data= np.zeros((7, 1024, 1024))\n",
    "\n",
    "for i in range (0,7):\n",
    "    file = \"timedark\" + str(i) + \".FIT\"\n",
    "    timedark = fits.open(file)\n",
    "    current_dark=timedark[0].data\n",
    "    #print(current_dark)\n",
    "    for n in range(0,1024):\n",
    "        for j in range(0,1024):\n",
    "            data[i,n,j]=current_dark[n,j]\n",
    "\n",
    "\n",
    "#for n in range(0,7):\n",
    "#    current_image = data[n].flatten()\n",
    "#    print(n)\n",
    "#    plot=plt.hist(current_image,range=[900,upper_bound[i]], bins=80);\n",
    "#    plt.yscale('log')\n",
    "#    plt.show()\n",
    "upper_bound = [1025,1030,1050,1065,1075,1100,1120]\n",
    "\n",
    "data_within = []\n",
    "mu = []\n",
    "std = []\n",
    "statstd = []\n",
    "leftovermu = []\n",
    "for n in range(0,7):\n",
    "    current_data = data[n].flatten()\n",
    "    data_within.append(current_data[(current_data>=np.min(current_data)) & (current_data <= upper_bound[n])])\n",
    "    leftovermu.append(np.average(current_data[((current_data >= upper_bound[n])) & (current_data <= np.max(current_data))]))\n",
    "    mu.append(np.average(data_within[n]))\n",
    "    std.append(np.std(data_within[n]))\n",
    "    #print(data_within[n])\n",
    "    #print(mu[n])\n",
    "    #print(std[n])\n",
    "    statstd.append(std[n]/math.sqrt(len(data_within[n])))\n",
    "    #print(statstd[n])\n",
    "    #print(\"changed bounds\")\n",
    "    #data_within.append(current_data[(current_data >= np.min(current_data)) & (current_data <= (upper_bound[n]-50))])\n",
    "    #mu.append(np.average(data_within[n]))\n",
    "    #std.append(np.std(data_within[n]))\n",
    "    #print(data_within[n])\n",
    "    #print(mu[n])\n",
    "    #print(std[n])\n",
    "    #statstd.append(std[n]/math.sqrt(len(data_within[n])))\n",
    "    #print(statstd[n])\n",
    "print(mu)\n",
    "print(leftovermu)\n",
    "exptime = [10,30,50,70,90,110,130]\n",
    "\n",
    "#plt.errorbar(exptime, mu, yerr=statstd,fmt='o', label=\"data\")\n",
    "plt.errorbar(exptime, leftovermu, yerr=statstd,fmt='o', label=\"data\")\n",
    "plt.xlabel('Exposure time (s)')\n",
    "plt.ylabel('Average number of counts leftover')\n",
    "\n",
    "def func(x,a,b):\n",
    "    return a+b*x\n",
    "best_vals, covar = curve_fit(func, exptime, mu, sigma=statstd)\n",
    "a=best_vals[0]\n",
    "b=best_vals[1]\n",
    "\n",
    "\n",
    "x = np.linspace(0, 150, num=100)\n",
    "yfit = func(x,a,b)\n",
    "plt.plot(x,yfit,label=\"fit\")\n",
    "print(b)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
